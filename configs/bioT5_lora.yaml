model:
  pretrained_model: QizhiPei/biot5-base
  out_dir: biot5_qlora
  max_len: 256
  batch_size: 4
  lr: 2e-4
  n_epochs: 5
lora:
  enabled: True
  r: 32
  alpha: 32
  dropout: 0.05
  quantization: True
data:
  subset: 500 # None for all data
  dataset: derm_qa
  # dataset: medXpert
  # dataset: no_robots